# ddia

designing data-intensive application

从系统的读写两部分考虑，怎么设计一个可扩展、可维护、高可用的后台系统

[TOC]

## 一句话描述这本书

- 透过现象看本质的一本书，比如什么意味着实时，分布式，cap定理，acid？

## 要点

- page2，技术是一把双刃剑，既能固化利益集团，也能让底层人民发声
- page5，应对巨大流量、灵活多变的数据模型、免费和开源软件的成功、并行化程度加快、高可用，这些技术的进步使数据密集型应用更加完善
- page12，reliable（在大多数情况下提供正确的功能）、scalable（能有效应对系统增长）、maintainable（所有系统角色都能在不同时期在系统中高效工作）
- page13，data system相关组件
  - database
  - cache
  - search indexes
  - stream processing，异步处理
  - batch processing
- page14，各种组件的边界越来越模糊
- page17，软件错误和硬件错误，硬件错误基本是独立发生的，软件错误一般会有较大相关性
- page20，twitter如何实现followee发文，follower收文的？通过两种方式并行
- page24，水平横向扩展通常对于无状态的服务非常有用
- page32，数据模型：关系模型、文档模型和基于图的模型
- page39，多对多关系应该如何表示？是文档模型还是关系模型？
  - 模式固定大多数情况会采用关系型数据库，通信录
  - 模式不确定灵活多变采用非关系型数据库，社交网络，物流数据表
- page51，通过数据库表实现图模型
- page52，cypher查询语句和Neo4j图数据库
- page55，通过三元组实现图
- page67，两大类存储引擎，面向日志和面向页面的
- page68，面向日志的存储引擎需要处理的问题：
  - 回收磁盘空间防止日志无限增长
  - 并发控制
  - 处理错误，例如部分写入的记录
- page68，日志的定义：追加的记录序列
- page69，Bitcask，用hash索引，用csv格式记录数据。衍生出一个问题，日志分段，日志压缩（删除没用的数据也是压缩）
  - 文件格式：CSV，不好，最好使用二进制方式，快
  - 删除记录：追加一条删除记录日志（逻辑删除）
  - 崩溃恢复：在磁盘上存储hash快照，加速加载速度
  - 部分写入问题：通过分段文件校验和，检测和忽略日志被损坏的部分
  - 并发控制：一个写入线程，多个读取线程
- page71，追加比覆盖的方式的优势：
  - 崩溃恢复简单
  - 速度快
- page71，hash表索引的局限性
  - hash表必须放在内存
  - hash表无法进行范围读取
- page72，SSTable（sorted string table）排序表，LSM（Log-Structured Merged-tree）日志结构合并树
  - LSM日志合并树
  - 读，读memtable上的key对应的offset，通过offset到磁盘上着数据
  - 写，append记录到磁盘，更新memtable中key对应的offset
  - 整理，需要定期把磁盘上的数据整理成有序的
- page78，B树中通过WAL机制进行崩溃恢复，也可以通过COW的机制实现
  - 通过使用尽量小的索引来表示B树的每个节点，这样可以增加分支因子
  - B树的大量顺序关键字数据扫描可能会涉及到大量的磁盘查找，因为每个块并不是有序的，而LSM很容易做到
- page78，B树通常读取比较快，LSM通常写入比较快，LSM读取快是因为在压缩阶段进行读取时比较复杂
  - B树的一次写操作会包含多次磁盘写操作，即使一个页面只有几个字节变化也需要在磁盘写整个页面
  - LSM定期重写数据文件可以减少磁盘碎片
- page79，LSM的缺点
  - 压缩过程会影响正常读写，影响磁盘带宽
  - B树对事务的支持更好，而LSM例如Hbase对写入操作进行串行？
- page80，二级索引与heap file，索引一般不存储值，值存储在heap file上，当更新值的时候，如果值在heap file上的大小和需要更新的一致时，可以直接更新，如果不一致则需要插入操作，这会导致非常多的索引更新，或采用转发指针的方式
- page81，空间索引，R树，多维索引
- 这个sql的问题在于，需要走两次查询，一次拿出维度范围内的id，一次拿出经度范围内的id，再做一次merge

```sql
select * from restautrants where latitude > a and latitude < b and longitude > c and longitude < d;
```

- page82，在一定编辑距离内的搜索
- page82，内存数据库
- page83，反缓存技术，在内存不足时，通过最近最少使用算法把不需要留在内存中的数据存储在磁盘
- page83，OLTP，OLAP
  - 一般通过一个独立的数据仓库进行OLAP，这个数据仓库是从OLTP数据库ETL来的
- page88，事实表、维度表、星型分析模式、雪花型分析模式
  - 事实表，比如分析一个事件，会包含事件的发生地点、时间、方式和原因
  - 维度表，事实表中每一列对其他表的引用，例如事实表的一个列是已经出售的商品，一个商品又可以有其他属性，比如商品名等等
  - 星型就是说事实表在中间，其他维度表在周围
- page89，终于搞清楚了列存储的意思，行存储是按行进行存取，而列存储是把一列的数据存储在一起
  - 为什么会有这样的需求呢？因为进行OLAP的时候，我们并不需要拉取一行的数据出来分析，只需要某些字段就够了
- page90，列压缩：列经常会出现重复和空洞的单元
- page92，存储几个排序顺序和冗余数据
- page93，物化视图原来是用来做数据缓存用的！我就说搞那么多视图干嘛？通常搭配各种聚合函数使用
- page101，随着对需求的深入理解，或者商业环境的变化，总会出现软件上的增增改改的需求
- page104，语言内置序列化功能有很多局限性，例如：安全性、语言绑定、兼容性和性能问题
- page113，Avro，一种通过字段名对数据进行编码的编码方式，导致兼容旧数据格式只需要保证增加和删除的字段都是有默认值的就可以了
- page115，编码除了需要满足将内存对象序列化成字节流的安全性等问题，最重要的还是要满足兼容性
- page116，数据流有哪些类型？
  - 数据库数据流
  - 服务传输数据流
  - 消息传输数据流
- page117，数据库数据流可以想象成自己发送消息给未来的自己，需要注意旧的自己处理新的数据的问题
- page120，本地调用和远程调用的不同，本地调用是完全由参数控制的，远程调用有各种不同的网络等因素，需要进行重试等逻辑，此时就需要调用方支持幂等性了
- page122，消息传输的数据流和rpc相比，差异在于消息队列的消息传递方向是单向的，而且如果消息的接收方出现卡顿崩溃，消息可以缓存。消息也可以以广播的形式传递
- page123，actor编程模型，类似csp（communication sequence processing）减少线程并发产生的锁竞争等问题
- page131，replication和partition
- page135，replication算法：单领导者、多领导者和无领导者
  - 同步还是异步？
  - 如何处理失败的情况？
- page136，主/从复制
  - slave只从master拉取数据更改log，并应用数据更改
  - 写主库，从库只能读取
  - 模式
    - 完全同步复制，主失效时，任意从库可以替换，但有从库失效，写操作将无法进行
    - 半同步复制，只写一半以上的从库，是一种折衷的处理方法
    - 完全异步，优势在于所有从库失效，主库仍然能写
- page139，failover，故障切换
  - 主库自动切换的超时时间
  - 防止脑裂的出现
  - 保证新的主节点是拥有最新数据的节点
- page140，复制日志的实现
  - 基于语句的复制。如果有并发事务，则很难保证正确性，边界条件太多
  - 基于WAL的复制。WAL是追加的二进制日志，用于崩溃恢复用，大多数数据库都采用这种方法
  - 基于行的逻辑日志复制。对行的增删改进行同步，同时同步每一行的事务状态
  - 基于触发器的复制。数据库允许更加多的灵活性
- page143，什么是最终一致性？主从同步的过程中，由于异步同步会导致从库某一个时刻的状态是落后的，但是只要关闭写一段时间，从库能从主库将所有数据都同步过来，最终保持一致
- page144，分布式的读写一致性
  - 分场景，哪些需要读主库，哪些可以读从库，比如个人资料，本人应该读主库，读别人的资料可以读从库
  - 客户端决定多少时间内可以从从库中读，客户端拿到一个commit id，读的时候通过这个commit id和已经同步的commit id比较
  - 通过hash用户id到不同的从库，保证读的单调性（这个还是会发生混乱，因为某些从库复制的快，有些从库复制得慢的问题，page147）
- page150，多主复制。例如：可以离线工作的多人文档编辑
  - LWW，last writes wins
- page156，无主复制，客户端直接写多个副本
  - 读的时候也是读多个副本，如果之前写失败了，则会有一个反熵过程（副本之间进行同步）
- page176，分区的目标是读写负载均匀的分摊到各个节点上，避免热点问题
- page178，hash patitioning
- page179，负载倾斜（对于热点事件的写入）与消除热点，在热点事件的rowkey上加入随机数，这也带来了读取上的麻烦
- page180，二级索引，二级索引是按分区排序的，只管本分区的数据，所以文档分区索引也称为本地索引。二级索引的查询需要分散到所有分区，有scatter/gather两个阶段，分散/聚合
- page182，二级索引，也可以通过关键词索引，即每个分区只包含一定范围的关键词索引而不是所有的，这样可以加速查询
- page184，分区的reblancing
  - 最简单的方法，10个节点，建立100个分区，当增加一个节点的时候把之前10个节点每个节点的数据移动一部分到新的分区上
  - 按分区大小固定分配，即分区大小超过一定比例则分裂成两个分区Hbase
  - 按节点比例分区，即每个节点的分区数量固定，数据增加分区大小也随之增加
- page186，rebalancing这种情况属于意外情况，最好由运维自己做，不然容易导致级联失败
- page187，通过zk实现服务发现

## 问题

- page2，流行文化鄙视历史？
- page2，为了钱编写代码的人崇尚流行文化，流行文化是活在当下的文化，是不知道自己的文化从哪里来的文化？
- page5，Iaas，Infrastructure as a service，基础设施即服务

## related

- page16，磁盘阵列容错磁盘故障
- page22，SLO和SLA，服务级别目标，服务级别协议
  - 服务级别目标，描述服务需要达到的目标，例如99.9%的请求相应时间都要低于1s
  - 服务级别协议，为客户提供的协议，如果协议没有达到客户可以要求退款
- page22，排队延时，比如食堂排队十分钟，吃饭两分钟

## 衍生想做的事

- page82，学习Lucene引擎
- page82，RAMCloud
- page86，学习数据分析
- page90，位图编码数据压缩技术
- page104，最小公分母编码格式

## 思考

- 这本书写得也太好了把，人其实最需要的是知道来历，而不是直接丢给一坨知识给你，当知道为什么会有这个知识的时候，你就可以自己创造知识了
- 流式读取实际就是说顺序读取而不是随机读取
- 好的书是怎样的？就是能用最直白的语言表达最全面的道理