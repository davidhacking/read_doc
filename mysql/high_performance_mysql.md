# High performance mysql



### MySQL

- 基础设施组件

### 架构

- 第一层：连接层
  - 连接池：一个连接对应一个线程（NIO实现方式？）
  - 权限控制：db级、表级权限控制（缓存导致不生效的坑）
- 第二层：逻辑层
  - 解析器、优化器：可以使用explain查看mysql是如何优化的，通过hint的方式决定优化器的决策过程
    - 优化器居然会收集表数据的统计信息进行优化，而不关心是哪个存储引擎
  - 缓存：对解析结果和优化结果的缓存，对于一个已经解析的SQL语句会从缓存在直接获取结果
  - 并发控制（逻辑层）：
    - 锁，锁的管理本身就消耗着系统资源，包括获取锁、检查锁状态和释放锁
    - 锁队列用于管理读锁和写锁，
    - 表锁，非Innodb引擎支持read local锁在一个表read时进行数据修改，管理锁的成本最低
    - 行锁，锁开销最大，是现在引擎层
- 第三层：引擎层，mysql本身提供的：Innodb和NDB Cluster，第三方的：XtraDB和PBXT都是支持事务的引擎
  - 并发控制（引擎层）
  - 持久化：为每个schema在工作目录中分配一个子目录，frm保存表定义（每个table一个），

## 基本特性

### 事务与ACID

- 事务就是原子操作的一组SQL语句
  - 使用START TRANSACTION开始一个事务，COMMIT提交一个事务
  - 某些命令会强制提交当前事务，比如ALTER TABLE
  - 事务实现在引擎层，可以同时拥有MyISAM和Innodb的表，但是在数据回滚时MyISAM上修改的数据不会被回滚
  - Innodb为每个事务隐式加锁，在COMMIT或ROLLBACK的时候释放锁
  - 事务满足ACID四个性质
- 原子性（atomic）
- 一致性（consistency），数据库总是从一个一致性的状态转移到另一个一致性状态
- 隔离性（isolation），通常来说一个事务提交前的所有操作对于另一个事务是不可见的，通常来说很关键，因为这和你所使用的隔离级别有关
- 持久性（durability），事务提交后事务做的修改会提交到磁盘上做持久化
- 隔离级别
  - read uncommitted，读未提交
  - read commited，读提交，如果事务A在事务B执行的过程中执行，那么A会发生不可重复读的现象
  - read repeatable，可重复读，无法避免幻读现象，~~可重复读实际是通过锁住之前读的行来保证其他事务无法修改这些行~~（这只是我的想法，不知道一般化的实现，mysql通过MVCC肯定不是这样实现），但不能保证其他事务不插入数据，所以可能幻读到插入的数据，Innodb通过MVCC解决了此问题，因为我只读时间版本在我事务开始前的修改
  - serializable，串行化读取，在读取的每一行数据上都加锁，~~难道不是没有并发了，单线程完成每一个事务吗？~~

- MVCC
  - mysql的Innodb通过MVCC来不加锁实现RR
  - mysql为每一行数据添加三个自动，DB_TRX_ID, DB_ROLL_PTR, DB_ROW_ID，这三个字段可以表示两个含义：数据的创建时间和数据的删除时间
  - select，事务的开始时间>数据的创建时间，事务的开始时间<数据的删除时间，这些数据都是对该事务可见的
  - insert，把自己的版本号设置为创建时间
  - delete，把自己的版本号设置为删除时间
  - update，同时做insert和delete两个操作

- 死锁，当两个事务发生死锁时，Innodb会检测到死锁，并把其中一个持有锁最少的事务回滚
  - 回滚后的事务需要应用程序重新执行一遍，当然可以有自己的处理逻辑
- WAL机制，mysql使用WAL机制实现事务的持久化，持久化时先写内存，再由线程把内存中的数据持久化到事务日志（写日志时其实是追加方式写的，所以很快），并写数据库文件

## Schema与数据类型优化

逻辑设计、物理设计和查询设计

- 对于能够索引的列最好使用NOT NULL定义，不然NULL值其实会在索引时产生而外开销
- 只是用基本类型，数字、字符串、时间，mysql使用了很多别名，如bool其实和int是一个意思，区别只是在于合法性校验
- decimal采用bigint优化，例如需要精确到小数点后6位，可以x10^6后存bigint，decimal类型本身不支持CPU直接运算，mysql自己实现了一波decimal的高精度计算
- float，7个有效位，double，15个有效位，decimal，28个有效位
- varchar，在update varchar字段时，由于数据是变长的，Innodb会采用分裂页的方式来使行能放入页中
  - 适用于字符串的最大长度比平均长度大很多
  - varchar5和varchar200在存储hello时用的空间是一样的，但是varchar5能让mysql在排序和索引过程中有更加优秀的表现
- char（page152），在填充char字段的时候由于使用空格进行填充，所以存的时候是空格结尾，则空格会产生截断的感觉
- ENUM（page157），这个类型的实现实际是一个字符串关联一个int的方式，所以在联合查询的时候如果两边不是ENUM则会带来额外的overhead
- IP，IP实际是一个int值，所以通过INET_ATON和INET_NTOA进行转换是不错的选择

### [范式NF](https://blog.csdn.net/ljp812184246/article/details/50706596)

- 第一范式：每一列是不可分割的基本数据项
- 2NF（page165）：在1NF的基础上，非主属性完全依赖与主关键字
  - 例如：一张部门信息表：员工，部门，部门领导是不符合2NF的，因为在更新部门领导时需要更新多个数据
- 3NF，在2NF的基础上不存在A->B->C，如果有应该改成A->C的情况
- 反范式化，由于范式的存在就会有join表的情况，但这样又会影响查询性能，如果增加一个字段做成一个索引将可以更好地完成查询

### 汇总表、缓存表和物化视图

相对于符合NF的表，缓存表和汇总表做的事情实际是保存衍生的冗余数据，为了实现某些功能，例如：需求A和需求B，AB之间在需要建立的索引上可能时相互矛盾的，而且对于一张表而言建立太多的索引会导致更新数据的时候出现问题，这是就需要通过建立一些冗余数据的表来完成不同的需求

- 汇总表：例如为了统计协议接口访问的次数而建立一张不同时间、不同接口更新的表，对于统计一个网站的点击量的数据时，如果只写一张表的一个字段那就会产生单点问题，可以采用写多个字段的方法，在最后统计时做一次sum
- 缓存表：为了对某个字段进行全文检索而使用MyISAM实现
- 同一个数据进行了冗余存储在更新的时候就造成了麻烦，一种做法是使用影子表，实时通过查询的方式更新，或插入时指插入一张表，同步时通过删除之前的影子表的方式来更新影子表（page169）
- Flexviews是mysql上实现的比较成功的物化视图，通过读取binlog实现的，能够较好的解决影子表的建立的问题
  - 使用时通过定义不同的select语句flexviews会帮助你转换到相应的api完成操作

### 改变表结构

- 如果只是需要改变表中某列的默认值可以通过alter column实现，因为列的默认值是存在于frm文件中的

### B-Tree

- m阶的btree最多有m-1个孩子，最少有⌈m/2⌉个孩子，因为m阶最多有m个child

- 插入：尝试插入到子节点上，如果插入后子节点上key的数量不超过m个则插入完成，超过则分裂子节点，并递归插入**中间的数**到父节点上（父节点也满了则递归分裂）
  - 所以在数据量很大的时候插入，真的有可能使插入的成本贼高
- 删除：
- hash索引，在B-Tree上建立自适应hash，hash索引实际是对某一列做的一次hash，这样能够在等值判断的时候直接找到行数据，mysql会对于经常被访问的行数据在B-Tree索引的基础上做hash索引
  - 对url这种数据进行等值查找的时候非常慢，优化方法：插入一个hash索引（page185）

### R-Tree

- 空间索引，MyISAM支持，地理数据的索引

## 索引

### 全文索引

### 前缀索引page190

- 对varchar字段或blob、text字段采用前缀索引的方式，达到即可以过滤更多的行又可以节省索引空间的目的
- 前缀索引选择多少字节合适？1. 计算索引列的distinct值与总数的比值A 2. 尝试2、3、5和7等个数的前缀与总数的比值，比较比值的增长情况，例如：从5到7比值已经比较接近A了，那其实就选择5就行了
- 添加某列的前缀索引，alter table table add key (col(PREFIX_LEN))
- 前缀索引并不能做order by和group by，也无法做覆盖扫描
- 后缀索引，通过把前缀索引反向存储一遍

### 如果建立高效索引page194

- where条件中的and的字段，采用联合索引，即一个包含多列的索引
- where条件中的or的字段，这个并不是采用独立索引就好了，因为涉及到数据排序与合并，mysql会将数据进行合并，如果没写好mysql会全表扫描
  - 老版本：A or B = A or (B and ~A)通过两个sql查询出来再将结果合并，这样mysql才会使用索引
  - 新版本：mysql可以帮你完成老版本的功能，不需要你写难懂的sql，但做法是一样的
  - 可以通过explain sql\G的Extra字段查看mysql是怎么处理的，有没有用你的索引，三种做法：union、intersection和两者组合
- 作者最后评价，mysql做的这个优化合并索引还不如自己写union sql，经常出了问题查不了，关闭方法：optimizer_switch，或在查询时通过ignore index的方式忽略掉某些索引
- page196，**建立索引的列顺序**，如果在建立索引前不知道应该使用哪一列在前，则使用区分度较高的列在前面
- page207，如果使用auto_increment作为主键则会导致并发插入时锁的竞争，innodb可以采用[innodb_autoinc_lock_mode](http://seanlook.com/2017/02/16/mysql-autoincrement/)配置
  - mode 0，获取表锁*AUTO-INC*，在一个事务中插入时只要insert完立马释放锁，不会出现空洞
  - mode 1，对于能够估算插入数量，然后批量自增，如果事务回滚会出现空洞
  - mode 2，不加锁，插入时会出现duplicate key error的问题，但是并发行高
- page210，覆盖索引的优化，对于需要回表的二级索引，可以采用先过滤不需要回表的列，再通过主键回表的方法进行优化
  - 疑问：为啥那个优化的title like语句不是放在外面
- page240，msyql的执行过程
- page251，对于select语句生成的执行代码，嵌套循环关联策略
- page256，可以使用mysql hint告诉mysql如何执行sql语句
- page257，通过max_length_for_sort_data来控制使用两次传输排序还是单次传输排序
- page260，select * from table where col in (select id from table2)，这个查询只会被改写成子查询，可以通过explain的type和possible_keys看出来，此时可以通过修改为关联查询的方式来优化
- page268，通过关联临时表的方式来实现在同一个表上进行查询和更新
- page274，一些编写sql语句的技巧
- page275，关联查询的优化
- page276，子查询会利用临时表填充中间结果，临时表上没有索引
- page277，在使用group by的情况下如果没有order by则默认会使用group by的字段进行排序，如果在group by字段上没有索引，则会使用filesort排序，可以使用order by null的方式避免
- page278，优化分页，当分页的页数很多的时候，需要扫描非常多的无用记录，可以通过子查询的延迟关联方式使扫描的记录不需要回表
- page282，使用mysql变量提升select性能，也是sql语句的技巧
- page286，sql语句的技巧
- page292，使用in语句优化两个float型数据的between查找

### Innodb

- page53，RR的实现机制，通过next-key locking（间隙锁）策略防止行的插入，即锁定了查询的数据和索引
- 聚簇索引，索引数据与行数据按顺序关联存储，非聚簇索引，索引中存放行数据所在地址
  - 有点，减少磁盘IO
- 自适应hash索引，如果某个二级索引被频繁访问则会建立hash索引提升访问速度
- 不支持热备份

### MyISAM

- 不支持事务，无法安全恢复
- 加锁，对表加锁，加写锁的表可以完成concurrent insert
- 存储，数据文件（myd）和索引文件（myi），支持表压缩
- 支持对blob和text前500个字符创建索引

### NDB

- mysql集群

### 分区表

- 在数据量超级大的情况下，索引是没有用处的
- 适合大数据处理，把表和索引水平分解（一行记录存储在统一物理分区上）为更小的部分，可以在不同的磁盘上
- page301，分区表在做所有操作前都需要打开并锁住所有底层表，这个操作是在过滤分区表之前
- page298，几种避免利用分区数据避免热点的方法
- page300，避免关联分区表时，需要扫描所有分区

### 视图

最好别用视图，高性能的查询中，视图就是个弟弟，很难优化，因为视图中可能没有关联查询的索引，此时，mysql会通过临时表实现，如果mysql将视图表作为关联顺序的第一个表，会导致没用上本来能用的索引，降低性能

- page307，mysql视图的实现有两种算法，一种仅仅是一个select语句，另一种是通过临时表的方式实现
- page309，通过视图实现列权限控制

### 外键

- page311，innodb几乎是mysql唯一支持外键的引擎，使用外键后，每次插入主表都需要在外键表产生一次查找操作
- innodb强制外键使用索引，所以当外键表的主键很大时，会导致外键的索引也很大（主键+外键列的索引）
- 如果只是用外键做约束条件，通过应用程序实现会好很多，而且使用外键可能会导致死锁等问题，因为每次都需要检查约束，而且这样的死锁难以排查

### mysql存储代码

mysql存储代码使用的最大问题其实是：当出现问题的时候难以排查

- page321，定时任务、触发器、存储过程、存储函数，他们的区别在于输入和输出。。。后面两个可以接受参数然后处理并返回。
- 利用mysql存储代码来写一些逻辑明显扩展性和通用型都很差，而且开发难度也更大，不过存储过程也有它的优势，那就是不需要额外的网络、sql解析和优化器开销，执行效率会快很多
- 触发器一般在insert、update和delete时出发一些操作

### 游标

server side curser和client side curser

### 通过绑定变量来优化性能

- prepared statement，在查询的时候会设置where子句中的某个字段是什么值，然后发给mysql server查询，mysql需要解析这个sql语句，然后转化成执行计划，通过使用绑定变量能够让mysql缓存执行计划
- page322，通过mysql命令行体验绑定变量

### 关于字符集

- 字符集，对于不用开发mysql，例如UDF，这部分只要控制好：1.创建数据库表的字符集选择；2.读写数据库表的字符集选择；3.如果用utf8编码的表存储一个CHAR(10)的数据，最多需要30个字节。就可以了。如果真的要处理两张表使用了不同的字符集，然后还要进行联合查询，我只能呵呵了
- 关于索引，一般单个字段的索引长度是787左右，如果CHAR(256)并使用了utf8编码，这个字段就不适合索引了，因为超过了最大索引长度，当然可以在创建表的时候指定某个字段的索引长度
- page333，通过order by xxx COLLATE utf8_bin可以指定字符集排序的方式

### 全文索引

- 全文索引，一般不会在innodb里用吧，考虑使用ES来做这件事了
- page339，原来布尔索引就是在搜索的时候加一些逻辑运算符进行搜索，例如“+”表示必须包含该关键词

### 分布式事务

- 2PC，Two Phase Commitment Protocol，先确定每个资源是否ready，即prepare阶段，如果都ready则提交，否则回滚
- XA的性能很差，因为需要等所有数据都被锁住
- 内部XA，内部XA是由binlog和引擎同时实现的，当引擎prepare后，由binlog commit。内部XA是mysql内部实现的，不需要应用程序参与
- 外部XA，相当于一个分布式mysql的代理，由应用层自己实现

### 缓存

- 查询缓存，对于相同的sql语句的查询结果，如果表数据没变，没必要再执行一次查询计划，mysql如果开启了查询缓存，则会进行缓存，缓存的key=数据库，客户端协议版本，sql语句本身
- 缓存的使用也需要结合查询进行分析，开启缓存后读表时，必先判断是否缓存，写表时有需要进行缓存失效，而缓存失效需要加锁
- Innodb的缓存，由于Innodb是基于mvcc实现的，所以mysql通过事务id和锁进行判断是否能读写缓存

### 优化mysql配置

- page361，第一段话就说到我心坎里去了，学习任何行为都应该从理解内核的行为开始，虽然这样会花很多时间，但是这样能解决问题
- 不要轻易修改配置，除非一定要修改，通常优化表结构，优化索引就能提升性能了

### 命令

- 查看表定义，show create table

- 查看表状态，show table status

  - row_format，Dynamic表示行中包含变长字符串
  - rows，行数，在Innodb中这个是个估计值，其他是精确值
  - avg_row_length，每行包含的字节数
  - data_length，表数据的大小
  - max_data_length，表数据的最大容量，表现为文件系统单个文件的大小
  - auto_increment，下一个自增值
  - create_time，创建时间
  - update_time，修改时间
  - check_time，使用check table命令的时间
  - collection，字符集和字符排序
  - checksum，整个表的实时校验和，这个开启会有性能影响吧，是吧每一行计算一个校验和，字段顺序不同也是有影响
- explain
  - [返回字段的含义](https://segmentfault.com/a/1190000008131735)，[官方](https://dev.mysql.com/doc/refman/8.0/en/explain-output.html#explain-output-columns)
  - select_type，primary查询是最外层的查询，derived字表查询
  - patitions，分区
  - type，连接方式，多表是连接方式，单表是查找方式？其实是一个包含关系
    - const，直接使用主键或index获取row的时候就是const的方式
    - eq_ref，两个表的连接方式是主键
    - ref，利用key column筛选key
    - range，between，in和等值判断
    - index和all
  - extra info
    - using index，索引覆盖查询，不需要回表，查询二级索引树就可以了
  - possible_keys，可能用到的key，如果没有可用的，可能需要自己去建立一下索引
  - key，实际使用的key
  - key_len，实际使用的索引的字节数

## 思考

- 为什么要看源码？其实是为了了解原理，了解原理也可以通过看书、看资料，那为什么要了解原理呢？因为一个功能的实现，一般都会有很多隐含逻辑，如果没弄清楚隐含逻辑就用，那就是瞎用，只会不断踩坑